{"cells":[{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Data Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 94379 entries, 0 to 94378\n","Data columns (total 25 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   ID                       94379 non-null  int64  \n"," 1   Overall_Experience       94379 non-null  int64  \n"," 2   Seat_comfort             94318 non-null  object \n"," 3   Seat_Class               94379 non-null  object \n"," 4   Arrival_time_convenient  85449 non-null  object \n"," 5   Catering                 85638 non-null  object \n"," 6   Platform_location        94349 non-null  object \n"," 7   Onboardwifi_service      94349 non-null  object \n"," 8   Onboard_entertainment    94361 non-null  object \n"," 9   Online_support           94288 non-null  object \n"," 10  Onlinebooking_Ease       94306 non-null  object \n"," 11  Onboard_service          86778 non-null  object \n"," 12  Leg_room                 94289 non-null  object \n"," 13  Baggage_handling         94237 non-null  object \n"," 14  Checkin_service          94302 non-null  object \n"," 15  Cleanliness              94373 non-null  object \n"," 16  Online_boarding          94373 non-null  object \n"," 17  Gender                   94302 non-null  object \n"," 18  CustomerType             85428 non-null  object \n"," 19  Age                      94346 non-null  float64\n"," 20  TypeTravel               85153 non-null  object \n"," 21  Travel_Class             94379 non-null  object \n"," 22  Travel_Distance          94379 non-null  int64  \n"," 23  DepartureDelay_in_Mins   94322 non-null  float64\n"," 24  ArrivalDelay_in_Mins     94022 non-null  float64\n","dtypes: float64(3), int64(3), object(19)\n","memory usage: 18.7+ MB\n","None\n","\n","Test Data Info:\n","<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 35602 entries, 0 to 35601\n","Data columns (total 26 columns):\n"," #   Column                   Non-Null Count  Dtype  \n","---  ------                   --------------  -----  \n"," 0   ID                       35602 non-null  int64  \n"," 1   Seat_comfort             35580 non-null  object \n"," 2   Seat_Class               35602 non-null  object \n"," 3   Arrival_time_convenient  32277 non-null  object \n"," 4   Catering                 32245 non-null  object \n"," 5   Platform_location        35590 non-null  object \n"," 6   Onboardwifi_service      35590 non-null  object \n"," 7   Onboard_entertainment    35594 non-null  object \n"," 8   Online_support           35576 non-null  object \n"," 9   Onlinebooking_Ease       35584 non-null  object \n"," 10  Onboard_service          32730 non-null  object \n"," 11  Leg_room                 35577 non-null  object \n"," 12  Baggage_handling         35562 non-null  object \n"," 13  Checkin_service          35580 non-null  object \n"," 14  Cleanliness              35600 non-null  object \n"," 15  Online_boarding          35600 non-null  object \n"," 16  Unnamed: 16              0 non-null      float64\n"," 17  Overall_Experience       35602 non-null  int64  \n"," 18  Gender                   35572 non-null  object \n"," 19  CustomerType             32219 non-null  object \n"," 20  Age                      35591 non-null  float64\n"," 21  TypeTravel               32154 non-null  object \n"," 22  Travel_Class             35602 non-null  object \n"," 23  Travel_Distance          35602 non-null  int64  \n"," 24  DepartureDelay_in_Mins   35573 non-null  float64\n"," 25  ArrivalDelay_in_Mins     35479 non-null  float64\n","dtypes: float64(4), int64(3), object(19)\n","memory usage: 7.3+ MB\n","None\n"]}],"source":["import pandas as pd\n","\n","# Load train datasets\n","survey_train = pd.read_csv(\"Surveydata_train.csv\")\n","travel_train = pd.read_csv(\"Traveldata_train.csv\")\n","\n","# Load test datasets\n","survey_test = pd.read_csv(\"Surveydata_test.csv\")\n","travel_test = pd.read_csv(\"Traveldata_test.csv\")\n","\n","# Merge train datasets\n","train_data = pd.merge(survey_train, travel_train, on=\"ID\")\n","\n","# Merge test datasets\n","test_data = pd.merge(survey_test, travel_test, on=\"ID\")\n","\n","# Display information about the merged datasets\n","print(\"Train Data Info:\")\n","print(train_data.info())\n","print(\"\\nTest Data Info:\")\n","print(test_data.info())\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Define columns for different types of preprocessing\n","numeric_features = ['Age', 'Travel_Distance', 'DepartureDelay_in_Mins', 'ArrivalDelay_in_Mins']\n","categorical_features = ['Seat_comfort', 'Seat_Class', 'Arrival_time_convenient', 'Catering', 'Platform_location',\n","                        'Onboardwifi_service', 'Onboard_entertainment', 'Online_support', 'Onlinebooking_Ease',\n","                        'Onboard_service', 'Leg_room', 'Baggage_handling', 'Checkin_service', 'Cleanliness',\n","                        'Online_boarding', 'Gender', 'CustomerType', 'TypeTravel', 'Travel_Class']\n","\n","# Define preprocessing steps for numeric and categorical features\n","numeric_transformer = SimpleImputer(strategy='median')\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","# Apply preprocessing steps to the appropriate columns\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)\n","    ])\n","\n","# Apply preprocessing pipeline to train data\n","X_train = train_data.drop(columns=['ID', 'Overall_Experience'])\n","y_train = train_data['Overall_Experience']\n","\n","# Apply preprocessing pipeline to test data\n","X_test = test_data.drop(columns=['ID'])\n"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Data Evaluation:\n","Accuracy: 0.8896576568940124\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.88      0.87      0.88     42786\n","           1       0.90      0.90      0.90     51593\n","\n","    accuracy                           0.89     94379\n","   macro avg       0.89      0.89      0.89     94379\n","weighted avg       0.89      0.89      0.89     94379\n","\n"]}],"source":["from sklearn.metrics import accuracy_score, classification_report\n","\n","# Predict the target variable for the train data\n","y_train_pred = pipeline.predict(X_train)\n","\n","# Evaluate the model on the train data\n","accuracy_train = accuracy_score(y_train, y_train_pred)\n","report_train = classification_report(y_train, y_train_pred)\n","\n","# Print the evaluation results for train data\n","print(\"Train Data Evaluation:\")\n","print(\"Accuracy:\", accuracy_train)\n","print(\"Classification Report:\\n\", report_train)\n","\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions saved to predictions.csv.\n"]}],"source":["# Predict the target variable for the test data\n","y_test_pred = pipeline.predict(X_test)\n","\n","# Create a DataFrame to store the predictions along with the corresponding IDs\n","predictions_df = pd.DataFrame({'ID': test_data['ID'], 'Predicted_Overall_Experience': y_test_pred})\n","\n","# Save the predictions to a CSV file\n","predictions_df.to_csv('predictions.csv', index=False)\n","\n","print(\"Predictions saved to predictions.csv.\")\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["         ID  Predicted_Overall_Experience\n","0  99900001                             1\n","1  99900002                             0\n","2  99900003                             1\n","3  99900004                             0\n","4  99900005                             1\n"]}],"source":["# Display the predictions DataFrame\n","print(predictions_df.head())\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions saved to predictions.csv.\n"]}],"source":["# Save the predictions to a CSV file\n","predictions_df.to_csv('predictions.csv', index=False)\n","\n","print(\"Predictions saved to predictions.csv.\")"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions saved to predictions.csv.\n"]}],"source":["# Map predicted numerical values to labels\n","overall_experience_mapping = {\n","    1: 'delighted',\n","    0: 'disappointed'\n","}\n","predictions_df['Predicted_Overall_Experience'] = predictions_df['Predicted_Overall_Experience'].map(overall_experience_mapping)\n","\n","# Save the predictions to a CSV file\n","predictions_df.to_csv('predictions.csv', index=False)\n","\n","print(\"Predictions saved to predictions.csv.\")\n"]}],"metadata":{"kernelspec":{"display_name":"tensorflow-gpu","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":2}
